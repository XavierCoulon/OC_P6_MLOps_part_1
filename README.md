# ğŸ‰ Projet MLOps - PrÃ©diction de Tirs au Rugby

## ğŸ“‹ Vue d'ensemble

Ce projet implÃ©mente un pipeline MLOps complet pour prÃ©dire la rÃ©ussite des tirs au rugby en utilisant diffÃ©rents modÃ¨les de machine learning. Le projet utilise **MLflow** pour le suivi des expÃ©riences et des artefacts, et **SHAP** pour l'interprÃ©tabilitÃ© des modÃ¨les.

### Objectifs

-   Comparer plusieurs modÃ¨les de classification
-   Optimiser les hyperparamÃ¨tres avec GridSearchCV
-   Appliquer des techniques de rÃ©Ã©quilibrage (SMOTE)
-   Fournir des explications via SHAP
-   Tracer tous les modÃ¨les et mÃ©triques dans MLflow

---

## ğŸš€ Installation

### PrÃ©requis

-   Python 3.8+
-   `uv` (gestionnaire de paquets ultra-rapide)

### Installation avec `uv`

1. **Cloner le projet**

```bash
git clone <repo-url>
cd OC_P6_Rugby_MLOps
```

2. **Installer les dÃ©pendances avec uv**

```bash
uv pip install -r requirements.txt
```

Ou directement avec uv:

```bash
uv sync
```

3. **VÃ©rifier l'installation**

```bash
python --version
uv pip list | grep -E "mlflow|shap|scikit-learn"
```

### DÃ©pendances principales

-   **mlflow**: Suivi des expÃ©riences et versioning des modÃ¨les
-   **scikit-learn**: ModÃ¨les et mÃ©triques
-   **xgboost**: Gradient boosting
-   **shap**: InterprÃ©tabilitÃ© des modÃ¨les
-   **imbalanced-learn**: SMOTE pour rÃ©Ã©quilibrage
-   **pandas, numpy**: Manipulation de donnÃ©es
-   **matplotlib, seaborn**: Visualisations
-   **rich**: Affichage formatÃ© en terminal

---

## ğŸ“ Structure du projet

```
OC_P6_Rugby_MLOps/
â”œâ”€â”€ README.md                          # Ce fichier
â”œâ”€â”€ config.py                          # Configuration globale (paths, constantes)
â”œâ”€â”€ utils.py                           # Fonctions utilitaires (mÃ©triques, etc.)
â”œâ”€â”€ main.py                            # Script principal (optionnel)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                           # DonnÃ©es brutes
â”‚   â”œâ”€â”€ interim/                       # DonnÃ©es nettoyÃ©es
â”‚   â””â”€â”€ processed/                     # DonnÃ©es prÃªtes pour le modÃ¨le
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb                   # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_features.ipynb              # Feature Engineering
â”‚   â”œâ”€â”€ 03_modeling.ipynb              # Benchmark de 5 modÃ¨les
â”‚   â”œâ”€â”€ 04_xgboost_finetuning.ipynb    # Fine-tuning XGBoost + SHAP
â”‚   â”œâ”€â”€ 05_lr_finetuning.ipynb         # Fine-tuning LogisticRegression + SHAP
â”‚   â””â”€â”€ 06_lr_final_model.ipynb        # ModÃ¨le final LR avec Feature Engineering + SHAP
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figures/                       # Graphiques gÃ©nÃ©rÃ©s
â”‚   â””â”€â”€ reports/                       # Rapports d'analyse
â”‚
â””â”€â”€ mlruns/                            # Artefacts MLflow (gÃ©nÃ©rÃ© automatiquement)
```

---

## ğŸ““ Notebooks expliquÃ©s

### 1ï¸âƒ£ **01_eda.ipynb** - Exploratory Data Analysis

**Objectif**: Comprendre les donnÃ©es brutes

-   Analyse statistique descriptive
-   Distribution des classes
-   Visualisation des features
-   DÃ©tection des valeurs manquantes
-   CorrÃ©lations entre features

**RÃ©sultat**: Dataset compris et prÃªt pour feature engineering

---

### 2ï¸âƒ£ **02_features.ipynb** - Feature Engineering

**Objectif**: CrÃ©er et transformer les features

-   CrÃ©ation de `difficulty_score` = distance Ã— angle
-   CrÃ©ation de `foot_side_match` = correspondance pied/cÃ´tÃ©
-   Analyse de corrÃ©lation
-   SÃ©lection des features pertinentes

**RÃ©sultat**: Dataset enrichi `kicks_ready_for_model.csv`

---

### 3ï¸âƒ£ **03_modeling.ipynb** - Benchmark de modÃ¨les

**Objectif**: Comparer 5 modÃ¨les baseline

ModÃ¨les testÃ©s:

1. **DummyClassifier** - Baseline
2. **LogisticRegression** - ModÃ¨le linÃ©aire
3. **RandomForest** - Ensemble basÃ© arbres
4. **SVM** - Support Vector Machine
5. **XGBoost** - Gradient boosting

Pour chaque modÃ¨le:

-   EntraÃ®nement avec cross-validation
-   Matrice de confusion
-   Courbes ROC et Precision-Recall
-   Feature importances
-   Logging dans MLflow

**RÃ©sultat**: Meilleur modÃ¨le identifiÃ© (gÃ©nÃ©ralement XGBoost)

---

### 4ï¸âƒ£ **04_xgboost_finetuning.ipynb** - Fine-tuning XGBoost

**Objectif**: Optimiser les hyperparamÃ¨tres d'XGBoost

Ã‰tapes:

1. Preprocessing (StandardScaler)
2. **SMOTE** pour rÃ©Ã©quilibrer les classes
3. GridSearchCV avec 16 combinaisons (grille rÃ©duite)
4. EntraÃ®nement du meilleur modÃ¨le
5. **SHAP Analysis** complÃ¨te:
    - Summary plots (Bar + Bee swarm)
    - Dependence plots
    - Force plots (explication par prÃ©diction)
    - Waterfall plots

**HyperparamÃ¨tres optimisÃ©s**:

-   n_estimators, max_depth, learning_rate
-   subsample, colsample_bytree, min_child_weight

**RÃ©sultat**: ModÃ¨le XGBoost optimisÃ© avec explications SHAP

---

### 5ï¸âƒ£ **05_lr_finetuning.ipynb** - Fine-tuning LogisticRegression

**Objectif**: Optimiser LogisticRegression avec SMOTE

Ã‰tapes similaires Ã  NB04:

1. Preprocessing
2. SMOTE
3. GridSearchCV (24 combinaisons: lbfgs+l2, liblinear+l1/l2)
4. EntraÃ®nement
5. **SHAP Analysis** avec LinearExplainer:
    - Summary plots
    - Dependence plots
    - Force plots
    - Waterfall plots

**HyperparamÃ¨tres optimisÃ©s**:

-   solver (lbfgs, liblinear)
-   C (rÃ©gularisation)
-   penalty (l1, l2)
-   max_iter

**RÃ©sultat**: ModÃ¨le LogisticRegression optimisÃ© avec SHAP

---

### 6ï¸âƒ£ **06_lr_final_model.ipynb** - ModÃ¨le final avec Feature Engineering

**Objectif**: Produire le meilleur modÃ¨le avec Feature Engineering intÃ©grÃ©

SpÃ©cificitÃ©s:

-   **Feature Engineering appliquÃ©e** dÃ¨s le dÃ©part:

    -   difficulty_score
    -   foot_side_match
    -   Analyse de corrÃ©lation

-   **Analyse des seuils optimaux**:

    -   Courbe Precision-Recall avec seuil optimal
    -   Seuil maximisant la prÃ©cision avec recall â‰¥ 0.60
    -   Visualisation du point optimal

-   **SHAP Analysis complÃ¨te**:

    -   6 visualisations (comme NB04/05)
    -   Explications par prÃ©diction
    -   Impact des features

-   **Tag MLflow**: `feature_engineering: applied`

**RÃ©sultat**: ModÃ¨le de production avec explications complÃ¨tes

---

## ğŸ” Configuration (config.py)

Fichier de constantes globales:

```python
PROCESSED_DATA_PATH = "data/processed/kicks_ready_for_model.csv"
TARGET_COL = "is_goal"  # Variable cible
SEED = 42  # ReproductibilitÃ©
FIG_DIR = "outputs/figures"  # Dossier des graphiques
CV_STRATEGY = StratifiedKFold(n_splits=5)  # Cross-validation
```

---

## ğŸ“Š MLflow - Suivi des expÃ©riences

### DÃ©marrer MLflow UI

```bash
mlflow ui --backend-store-uri file:./mlruns
```

Puis ouvrir: `http://localhost:5000`

### Structure MLflow

```
ExpÃ©riences:
â”œâ”€â”€ Rugby Kicks - Benchmark Models (NB03)
â”œâ”€â”€ Rugby Kicks - XGBoost Finetuning (NB04)
â”œâ”€â”€ Rugby Kicks - LogisticRegression Finetuning (NB05)
â””â”€â”€ Rugby Kicks - LogisticRegression Final Model (NB06)

Chaque run contient:
â”œâ”€â”€ ParamÃ¨tres (hyperparamÃ¨tres)
â”œâ”€â”€ MÃ©triques (accuracy, F1, AUC, etc.)
â”œâ”€â”€ Artefacts:
â”‚   â”œâ”€â”€ ModÃ¨le entraÃ®nÃ©
â”‚   â”œâ”€â”€ Matrices de confusion
â”‚   â”œâ”€â”€ Courbes ROC/PR
â”‚   â””â”€â”€ SHAP visualizations
â””â”€â”€ Tags (metadata)
```

---

## ğŸ“ˆ ExÃ©cution des notebooks

### Option 1: Notebooks Jupyter

```bash
jupyter notebook
```

Puis naviguer vers le notebook souhaitÃ© et exÃ©cuter les cellules.

### Option 2: Scripts Python

```bash
python -m jupyter nbconvert --to script notebooks/03_modeling.ipynb
python 03_modeling.py
```

### Ordre recommandÃ© d'exÃ©cution

1. **01_eda.ipynb** - Exploration
2. **02_features.ipynb** - Feature engineering
3. **03_modeling.ipynb** - Benchmark
4. **04_xgboost_finetuning.ipynb** - Fine-tuning XGBoost
5. **05_lr_finetuning.ipynb** - Fine-tuning LR
6. **06_lr_final_model.ipynb** - ModÃ¨le final

---

## ğŸ› ï¸ Utilitaires (utils.py)

### Fonctions principales

**`compute_train_test_metrics(y_train, y_pred_train, y_proba_train, y_test, y_pred, y_proba)`**

-   Calcule les mÃ©triques train et test
-   Retourne: metriques, confusion_matrix, (fpr, fnr)

**`extract_cv_metrics(cv_results)`**

-   Extrait les rÃ©sultats de cross-validation

---

## ğŸ¯ RÃ©sultats typiques

### Comparaison des modÃ¨les (NB03)

| ModÃ¨le             | Accuracy | F1-score | ROC-AUC  |
| ------------------ | -------- | -------- | -------- |
| Dummy              | ~50%     | -        | 0.50     |
| LogisticRegression | ~75%     | 0.72     | 0.82     |
| RandomForest       | ~77%     | 0.75     | 0.84     |
| SVM                | ~76%     | 0.74     | 0.83     |
| **XGBoost**        | **~80%** | **0.78** | **0.87** |

### AprÃ¨s fine-tuning + SMOTE

-   **XGBoost**: ~82-85% accuracy
-   **LogisticRegression**: ~80-82% accuracy

---

## ğŸ“Œ Tags MLflow

Chaque run est taguÃ© avec:

-   `author`: Xavier
-   `model_type`: xgboost_finetuned, logistic_regression_final, etc.
-   `optimization_method`: gridsearchcv
-   `resampling`: SMOTE
-   `feature_engineering`: applied (NB06 uniquement)
-   `search_strategy`: reduced_grid_option1 (NB04)

---

## âš™ï¸ Troubleshooting

### SHAP Analysis Ã©choue

**ProblÃ¨me**: `Exception in SHAP Analysis`

**Solutions**:

-   VÃ©rifier que `shap` est installÃ©: `uv pip install shap`
-   Les modÃ¨les trÃ¨s complexes peuvent poser problÃ¨me
-   Le code inclut une gestion d'erreur qui continue sans SHAP

### MLflow n'affiche pas les artifacts

**Solution**: VÃ©rifier le `FIG_DIR` dans `config.py`

```bash
ls -la outputs/figures/
```

### Memory issue avec GridSearchCV

**Solution**: RÃ©duire `n_jobs`:

```python
GridSearchCV(..., n_jobs=-1)  # Utilise tous les cores
# Ou
GridSearchCV(..., n_jobs=4)   # Limite Ã  4 cores
```

---

## ğŸ“š Ressources

-   [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
-   [SHAP Documentation](https://shap.readthedocs.io/)
-   [Scikit-learn](https://scikit-learn.org/)
-   [XGBoost](https://xgboost.readthedocs.io/)
-   [uv - Package Manager](https://docs.astral.sh/uv/)

---

## ğŸ“ Notes importantes

1. **ReproductibilitÃ©**: `SEED=42` est fixÃ© partout
2. **Data Leakage**: Preprocessing fit uniquement sur train
3. **SMOTE**: AppliquÃ© APRÃˆS split train/test
4. **MÃ©triques**: F1-weighted pour donnÃ©es imbalancÃ©es
5. **SHAP**: LinearExplainer pour modÃ¨les linÃ©aires, TreeExplainer pour arbres

---

## ğŸ¤ Contributions

Pour modifier le pipeline:

1. CrÃ©er une nouvelle branche: `git checkout -b feature/xyz`
2. Faire les modifications
3. Tester les notebooks
4. VÃ©rifier les runs MLflow
5. Commit et push

---

## ğŸ“„ Licence

Projet OpenClassrooms - Parcours AI Engineer

---

**DerniÃ¨re mise Ã  jour**: Novembre 2025
**Auteur**: Xavier
