# üèâ Projet MLOps - Pr√©diction de Tirs au Rugby

## üìã Vue d'ensemble

Ce projet impl√©mente un pipeline MLOps complet pour pr√©dire la r√©ussite des tirs au rugby en utilisant diff√©rents mod√®les de machine learning. Le projet utilise **MLflow** pour le suivi des exp√©riences et des artefacts, et **SHAP** pour l'interpr√©tabilit√© des mod√®les.

### Objectifs

-   Comparer plusieurs mod√®les de classification
-   Optimiser les hyperparam√®tres avec GridSearchCV
-   Appliquer des techniques de r√©√©quilibrage (SMOTE)
-   Fournir des explications via SHAP
-   Tracer tous les mod√®les et m√©triques dans MLflow

---

## üöÄ Installation

### Pr√©requis

-   Python 3.8+
-   `uv` (gestionnaire de paquets ultra-rapide)

### Installation avec `uv`

1. **Cloner le projet**

```bash
git clone <repo-url>
cd OC_P6_Rugby_MLOps
```

2. **Installer les d√©pendances avec uv**

```bash
uv pip install -r requirements.txt
```

Ou directement avec uv:

```bash
uv sync
```

3. **V√©rifier l'installation**

```bash
python --version
uv pip list | grep -E "mlflow|shap|scikit-learn"
```

### D√©pendances principales

-   **mlflow**: Suivi des exp√©riences et versioning des mod√®les
-   **scikit-learn**: Mod√®les et m√©triques
-   **xgboost**: Gradient boosting
-   **shap**: Interpr√©tabilit√© des mod√®les
-   **imbalanced-learn**: SMOTE pour r√©√©quilibrage
-   **pandas, numpy**: Manipulation de donn√©es
-   **matplotlib, seaborn**: Visualisations
-   **rich**: Affichage format√© en terminal

---

## üìÅ Structure du projet

```
OC_P6_Rugby_MLOps/
‚îú‚îÄ‚îÄ README.md                          # Ce fichier
‚îú‚îÄ‚îÄ config.py                          # Configuration globale (paths, constantes)
‚îú‚îÄ‚îÄ utils.py                           # Fonctions utilitaires (m√©triques, etc.)
‚îú‚îÄ‚îÄ main.py                            # Script principal (optionnel)
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                           # Donn√©es brutes
‚îÇ   ‚îú‚îÄ‚îÄ interim/                       # Donn√©es nettoy√©es
‚îÇ   ‚îî‚îÄ‚îÄ processed/                     # Donn√©es pr√™tes pour le mod√®le
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb                   # Exploratory Data Analysis
‚îÇ   ‚îú‚îÄ‚îÄ 02_features.ipynb              # Feature Engineering
‚îÇ   ‚îú‚îÄ‚îÄ 03_modeling.ipynb              # Benchmark de 5 mod√®les
‚îÇ   ‚îú‚îÄ‚îÄ 04_xgboost_finetuning.ipynb    # Fine-tuning XGBoost + SHAP
‚îÇ   ‚îú‚îÄ‚îÄ 05_lr_finetuning.ipynb         # Fine-tuning LogisticRegression + SHAP
‚îÇ   ‚îî‚îÄ‚îÄ 06_lr_final_model.ipynb        # Mod√®le final LR avec Feature Engineering + SHAP
‚îÇ
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ figures/                       # Graphiques g√©n√©r√©s
‚îÇ   ‚îî‚îÄ‚îÄ reports/                       # Rapports d'analyse
‚îÇ
‚îî‚îÄ‚îÄ mlruns/                            # Artefacts MLflow (g√©n√©r√© automatiquement)
```

---

## üìì Notebooks expliqu√©s

### 1Ô∏è‚É£ **01_eda.ipynb** - Exploratory Data Analysis

**Objectif**: Comprendre les donn√©es brutes

-   Analyse statistique descriptive
-   Distribution des classes
-   Visualisation des features
-   D√©tection des valeurs manquantes
-   Corr√©lations entre features

**R√©sultat**: Dataset compris et pr√™t pour feature engineering

---

### 2Ô∏è‚É£ **02_features.ipynb** - Feature Engineering

**Objectif**: Cr√©er et transformer les features

-   Cr√©ation de `difficulty_score` = distance √ó angle
-   Cr√©ation de `foot_side_match` = correspondance pied/c√¥t√©
-   Analyse de corr√©lation
-   S√©lection des features pertinentes

**R√©sultat**: Dataset enrichi `kicks_ready_for_model.csv`

---

### 3Ô∏è‚É£ **03_modeling.ipynb** - Benchmark de mod√®les

**Objectif**: Comparer 5 mod√®les baseline

Mod√®les test√©s:

1. **DummyClassifier** - Baseline
2. **LogisticRegression** - Mod√®le lin√©aire
3. **RandomForest** - Ensemble bas√© arbres
4. **SVM** - Support Vector Machine
5. **XGBoost** - Gradient boosting

Pour chaque mod√®le:

-   Entra√Ænement avec cross-validation
-   Matrice de confusion
-   Courbes ROC et Precision-Recall
-   Feature importances
-   Logging dans MLflow

**R√©sultat**: Meilleur mod√®le identifi√© (g√©n√©ralement XGBoost)

---

### 4Ô∏è‚É£ **04_xgboost_finetuning.ipynb** - Fine-tuning XGBoost

**Objectif**: Optimiser les hyperparam√®tres d'XGBoost

√âtapes:

1. Preprocessing (StandardScaler)
2. **SMOTE** pour r√©√©quilibrer les classes
3. GridSearchCV avec 16 combinaisons (grille r√©duite)
4. Entra√Ænement du meilleur mod√®le
5. **SHAP Analysis** compl√®te:
    - Summary plots (Bar + Bee swarm)
    - Dependence plots
    - Force plots (explication par pr√©diction)
    - Waterfall plots

**Hyperparam√®tres optimis√©s**:

-   n_estimators, max_depth, learning_rate
-   subsample, colsample_bytree, min_child_weight

**R√©sultat**: Mod√®le XGBoost optimis√© avec explications SHAP

---

### 5Ô∏è‚É£ **05_lr_finetuning.ipynb** - Fine-tuning LogisticRegression

**Objectif**: Optimiser LogisticRegression avec SMOTE

√âtapes similaires √† NB04:

1. Preprocessing
2. SMOTE
3. GridSearchCV (24 combinaisons: lbfgs+l2, liblinear+l1/l2)
4. Entra√Ænement
5. **SHAP Analysis** avec LinearExplainer:
    - Summary plots
    - Dependence plots
    - Force plots
    - Waterfall plots

**Hyperparam√®tres optimis√©s**:

-   solver (lbfgs, liblinear)
-   C (r√©gularisation)
-   penalty (l1, l2)
-   max_iter

**R√©sultat**: Mod√®le LogisticRegression optimis√© avec SHAP

---

### 6Ô∏è‚É£ **06_lr_final_model.ipynb** - Mod√®le final avec Feature Engineering

**Objectif**: Produire le meilleur mod√®le avec Feature Engineering int√©gr√©

Sp√©cificit√©s:

-   **Feature Engineering appliqu√©e** d√®s le d√©part:

    -   difficulty_score
    -   foot_side_match
    -   Analyse de corr√©lation

-   **Analyse des seuils optimaux**:

    -   Courbe Precision-Recall avec seuil optimal
    -   Seuil maximisant la pr√©cision avec recall ‚â• 0.60
    -   Visualisation du point optimal

-   **SHAP Analysis compl√®te**:

    -   6 visualisations (comme NB04/05)
    -   Explications par pr√©diction
    -   Impact des features

-   **Tag MLflow**: `feature_engineering: applied`

**R√©sultat**: Mod√®le de production avec explications compl√®tes

---

## üîê Configuration des variables d'environnement

### Fichier `.env`

Le projet utilise des variables d'environnement pour les configurations sensibles (tokens, chemins, etc.).

#### Cr√©er le fichier `.env`

```bash
cp .env.example .env
```

Puis remplir les variables selon vos besoins.

#### Variables disponibles

| Variable               | Description                             | Exemple                                        |
| ---------------------- | --------------------------------------- | ---------------------------------------------- |
| `PROJECT_ROOT`         | Chemin racine du projet                 | `/Users/xavier/Documents/OC/OC_P6_Rugby_MLOps` |
| `MLFLOW_TRACKING_URI`  | URI du tracking MLflow                  | `file:./mlruns`                                |
| `MLFLOW_MODEL_NAME`    | Nom du mod√®le dans le Registry          | `rugby-kicks-logistic-regression`              |
| `MLFLOW_MODEL_VERSION` | Version du mod√®le √† publier (optionnel) | `1` ou laisser vide                            |
| `HF_REPO_ID`           | ID du repository Hugging Face           | `XavierCoulon/rugby-kicks-model`               |
| `HF_TOKEN`             | Token d'authentification Hugging Face   | `hf_xxxxxxxxxxxxx`                             |

#### Exemple de `.env.example`

Voir le fichier `.env.example` pour un template complet avec explications.

---

## üöÄ Publication sur Hugging Face

### Pr√©requis

1. **Cr√©er un repository Hugging Face**:

    - Aller sur https://huggingface.co/new
    - Remplir le nom du repository
    - Choisir "Model"
    - Cliquer "Create repository"

2. **G√©n√©rer un token Hugging Face**:

    - Aller sur https://huggingface.co/settings/tokens
    - Cr√©er un nouveau token avec permissions "write"
    - Copier le token

3. **Remplir le `.env`**:
    ```env
    HF_REPO_ID=
    HF_TOKEN=
    MLFLOW_MODEL_VERSION=
    ```

### Lancer le script de publication

#### Option 1: Publier la derni√®re version en "Production"

```bash
# Laisser MLFLOW_MODEL_VERSION vide dans .env
python push_model_to_huggingface.py
```

#### Option 2: Publier une version sp√©cifique

```bash
# Remplir MLFLOW_MODEL_VERSION=1 dans .env
python push_model_to_huggingface.py
```

### √âtapes du script

1. ‚úÖ R√©cup√®re le mod√®le depuis MLflow (version sp√©cifi√©e ou derni√®re en Production)
2. ‚úÖ T√©l√©charge les artifacts (model, config, etc.)
3. ‚úÖ Publie sur Hugging Face

### R√©sultat

Le mod√®le est disponible sur: `https://huggingface.co/<HF_REPO_ID>`

---

Fichier de constantes globales:

```python
PROCESSED_DATA_PATH = "data/processed/kicks_ready_for_model.csv"
TARGET_COL = "is_goal"  # Variable cible
SEED = 42  # Reproductibilit√©
FIG_DIR = "outputs/figures"  # Dossier des graphiques
CV_STRATEGY = StratifiedKFold(n_splits=5)  # Cross-validation
```

---

## üìä MLflow - Suivi des exp√©riences

### D√©marrer MLflow UI

```bash
mlflow ui --backend-store-uri file:./mlruns
```

Puis ouvrir: `http://localhost:5000`

### Structure MLflow

```
Exp√©riences:
‚îú‚îÄ‚îÄ Rugby Kicks - Benchmark Models (NB03)
‚îú‚îÄ‚îÄ Rugby Kicks - XGBoost Finetuning (NB04)
‚îú‚îÄ‚îÄ Rugby Kicks - LogisticRegression Finetuning (NB05)
‚îî‚îÄ‚îÄ Rugby Kicks - LogisticRegression Final Model (NB06)

Chaque run contient:
‚îú‚îÄ‚îÄ Param√®tres (hyperparam√®tres)
‚îú‚îÄ‚îÄ M√©triques (accuracy, F1, AUC, etc.)
‚îú‚îÄ‚îÄ Artefacts:
‚îÇ   ‚îú‚îÄ‚îÄ Mod√®le entra√Æn√©
‚îÇ   ‚îú‚îÄ‚îÄ Matrices de confusion
‚îÇ   ‚îú‚îÄ‚îÄ Courbes ROC/PR
‚îÇ   ‚îî‚îÄ‚îÄ SHAP visualizations
‚îî‚îÄ‚îÄ Tags (metadata)
```

---

## üìà Ex√©cution des notebooks

### Option 1: Notebooks Jupyter

```bash
jupyter notebook
```

Puis naviguer vers le notebook souhait√© et ex√©cuter les cellules.

### Option 2: Scripts Python

```bash
python -m jupyter nbconvert --to script notebooks/03_modeling.ipynb
python 03_modeling.py
```

### Ordre recommand√© d'ex√©cution

1. **01_eda.ipynb** - Exploration
2. **02_features.ipynb** - Feature engineering
3. **03_modeling.ipynb** - Benchmark
4. **04_xgboost_finetuning.ipynb** - Fine-tuning XGBoost
5. **05_lr_finetuning.ipynb** - Fine-tuning LR
6. **06_lr_final_model.ipynb** - Mod√®le final

---

## üõ†Ô∏è Utilitaires (utils.py)

### Fonctions principales

**`compute_train_test_metrics(y_train, y_pred_train, y_proba_train, y_test, y_pred, y_proba)`**

-   Calcule les m√©triques train et test
-   Retourne: metriques, confusion_matrix, (fpr, fnr)

**`extract_cv_metrics(cv_results)`**

-   Extrait les r√©sultats de cross-validation

---

## üéØ R√©sultats typiques

### Comparaison des mod√®les (NB03)

| Mod√®le             | Accuracy | F1-score | ROC-AUC  |
| ------------------ | -------- | -------- | -------- |
| Dummy              | ~50%     | -        | 0.50     |
| LogisticRegression | ~75%     | 0.72     | 0.82     |
| RandomForest       | ~77%     | 0.75     | 0.84     |
| SVM                | ~76%     | 0.74     | 0.83     |
| **XGBoost**        | **~80%** | **0.78** | **0.87** |

### Apr√®s fine-tuning + SMOTE

-   **XGBoost**: ~82-85% accuracy
-   **LogisticRegression**: ~80-82% accuracy

---

## üìå Tags MLflow

Chaque run est tagu√© avec:

-   `author`: Xavier
-   `model_type`: xgboost_finetuned, logistic_regression_final, etc.
-   `optimization_method`: gridsearchcv
-   `resampling`: SMOTE
-   `feature_engineering`: applied (NB06 uniquement)
-   `search_strategy`: reduced_grid_option1 (NB04)

---

## ‚öôÔ∏è Troubleshooting

### SHAP Analysis √©choue

**Probl√®me**: `Exception in SHAP Analysis`

**Solutions**:

-   V√©rifier que `shap` est install√©: `uv pip install shap`
-   Les mod√®les tr√®s complexes peuvent poser probl√®me
-   Le code inclut une gestion d'erreur qui continue sans SHAP

### MLflow n'affiche pas les artifacts

**Solution**: V√©rifier le `FIG_DIR` dans `config.py`

```bash
ls -la outputs/figures/
```

### Memory issue avec GridSearchCV

**Solution**: R√©duire `n_jobs`:

```python
GridSearchCV(..., n_jobs=-1)  # Utilise tous les cores
# Ou
GridSearchCV(..., n_jobs=4)   # Limite √† 4 cores
```

---

## üìö Ressources

-   [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
-   [SHAP Documentation](https://shap.readthedocs.io/)
-   [Scikit-learn](https://scikit-learn.org/)
-   [XGBoost](https://xgboost.readthedocs.io/)
-   [uv - Package Manager](https://docs.astral.sh/uv/)

---

## üìù Notes importantes

1. **Reproductibilit√©**: `SEED=42` est fix√© partout
2. **Data Leakage**: Preprocessing fit uniquement sur train
3. **SMOTE**: Appliqu√© APR√àS split train/test
4. **M√©triques**: F1-weighted pour donn√©es imbalanc√©es
5. **SHAP**: LinearExplainer pour mod√®les lin√©aires, TreeExplainer pour arbres

---

## ü§ù Contributions

Pour modifier le pipeline:

1. Cr√©er une nouvelle branche: `git checkout -b feature/xyz`
2. Faire les modifications
3. Tester les notebooks
4. V√©rifier les runs MLflow
5. Commit et push

---

## üìÑ Licence

Projet OpenClassrooms - Parcours AI Engineer

---

**Derni√®re mise √† jour**: Novembre 2025
**Auteur**: Xavier
